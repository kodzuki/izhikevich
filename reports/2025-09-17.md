# ğŸ“ Reporte de sesiÃ³n â€“ Neurodelays

**Fecha:** 2025-09-18
**Participantes:** tÃº & GPT
**Contexto inicial:** DiscusiÃ³n de control de aleatoriedad y diseÃ±o de condiciones para estudiar el efecto de **distribuciones de retraso inter-poblaciÃ³n** en redes Izhikevich (2 ROIs), incluyendo caso **masterâ†’slave**.

---

## ğŸ¯ Objetivo de la sesiÃ³n

Acordar un **pipeline reproducible** que aÃ­sle el efecto de la **distribuciÃ³n de retrasos** (media/anchura/forma) separÃ¡ndolo de otras fuentes estocÃ¡sticas; definir la **simetrÃ­a/asimetrÃ­a** entre poblaciones para casos baseline y masterâ†’slave; y fijar criterios sobre **inputs** (Poisson/Gauss), **RNG/semillas** y **visualizaciÃ³n**.

---

## ğŸ› ï¸ Actividades realizadas

* Definimos un esquema de **bloques emparejados (CRN)**: dentro de cada bloque se congelan heterogeneidad, conectividad e input; solo cambia la **distribuciÃ³n de delays inter**. Entre bloques se re-muestrea todo para promediar.
* Aclaramos el uso de **TimedArray** y el efecto del **tamaÃ±o de bin** (dt pequeÃ±o â‰ˆ Poisson â€œcontinuoâ€).
* Decidimos cuÃ¡ndo **centrar** el input (Î¼=0) y cuÃ¡ndo usar **bombardeo excitatorio** (solo positivo) con fÃ³rmulas para ajustar **Î»** y **J** manteniendo varianza objetivo.
* DiseÃ±amos dos regÃ­menes de estructura de red:

  * **Baseline simÃ©trico** (clones o i.i.d.-simÃ©tricas).
  * **Masterâ†’slave** con asimetrÃ­a mÃ­nima (ruido/ganancia moderadamente distintos, inter Aâ†’B > Bâ†’A).
* Revisamos la implementaciÃ³n sinÃ¡ptica y el acoplamiento inter: recomendaciÃ³n de **sinapsis exponenciales** (Ï„\_syn corto) y **fuerza inter moderada** para no saturar.

---

## ğŸ“Š Resultados / hallazgos

* **Control de aleatoriedad efectivo**: usar CRN reduce la varianza entre condiciones y permite atribuir diferencias a la **distribuciÃ³n de delays**.
* **TimedArray/Poisson**: con dt grande aparecen **correlaciones por binning**; con dt pequeÃ±o (â‰¤0.1â€“0.5 ms) se aproxima al Poisson de punto.
* **Centrado vs bombardeo excitatorio**:

  * Para comparar delays de forma limpia, preferir **ruido centrado (Î¼â‰ˆ0)** con varianza controlada.
  * Si se usa bombardeo excitatorio, hay que **bajar mucho Î»** y ajustar **J** para igualar Ïƒ:

    * Î¼ = JÂ·Î», Ïƒ = JÂ·âˆšÎ» â‡’ **ÏƒÂ² = JÂ·Î¼**; elegir (Î¼\_target, Ïƒ\_target) y derivar (Î», J).
* **Masterâ†’slave**:

  * Mantener **asimetrÃ­as suaves** (p. ej., Ïƒ\_A â‰ˆ Ïƒ\_BÂ·1.1â€“1.2 o inter Aâ†’B 10â€“20% > Bâ†’A).
  * Evitar **p\_inter excesivo**: con p\_inter=0.05 se hiper-acopla y se pierde contraste entre distribuciones. Objetivo prÃ¡ctico: pico de xcorr â‰ˆ **0.3â€“0.5**.
  * La **anchura** de la distribuciÃ³n de delays deberÃ­a **ensanchar el pico de xcorr** y **reducir PLV/PLI/coherencia**, efecto mÃ¡s visible con **Ï„\_syn corto** (2â€“5 ms).
* **VisualizaciÃ³n/mediciÃ³n sin sobreactivar el acoplamiento**:

  * PSTH/STA de B disparado por picos en A; ordenar neuronas de B por **lag preferido**; overlay de **tasas poblacionales**; opcional, inyectar un **probe dÃ©bil** (seno/step) en A para estimar **ganancia/fase** en B.

---

## ğŸ“‚ Archivos/notebooks afectados

* `src/two_populations/model.py` â€” revisiÃ³n de sinapsis (volver a `on_pre: I_syn_post += w` + `dI_syn/dt = -I_syn/Ï„_syn`), RNG coherente en inter-pop.
* `src/two_populations/sweep.py` â€” estructura de **bloques emparejados** (CRN) y registro de artefactos por bloque (params, mÃ¡scaras, inputs).
* `src/two_populations/metrics.py` â€” confirmar warm-up y mÃ©tricas (xcorr, PLV/PLI, coherencia, Ï„ intrÃ­nseco).
* `configs/` â€” nuevas configs para **baseline simÃ©trico** y **masterâ†’slave**.
* `results/experiments/...` â€” salida organizada por **bloques** y **condiciones**.

---

## âœ… Decisiones tomadas

* **Baseline de comparaciÃ³n:** poblaciones **simÃ©tricas** (preferible â€œclonesâ€ en primera pasada); dentro de cada bloque solo cambia la **distribuciÃ³n de delays inter**.
* **Input para comparar delays:** **centrado (Î¼â‰ˆ0)** y â€œcongeladoâ€ por bloque; dt pequeÃ±o.
* **Masterâ†’slave:** introducir **asimetrÃ­a mÃ­nima** (Ïƒ o inter Aâ†’B > Bâ†’A), manteniendo acoplamiento **moderado** (objetivo xcorr 0.3â€“0.5).
* **ImplementaciÃ³n sinÃ¡ptica:** evitar `network_operation` a 1 ms (cuantiza y borra efecto de la anchura); usar **sinapsis exponenciales** con **Ï„\_syn corto**.
* **RNG/semillas:** separar flujos para (params, conectividad, inputs, estados) y **congelarlos** intra-bloque (CRN); re-muestrear entre bloques.

---

## ğŸ”œ PrÃ³ximos pasos

* [ ] Restaurar sinapsis con **decaimiento exponencial** y eliminar el â€œsample-and-holdâ€ a 1 ms.
* [ ] Calibrar **p\_inter** y `weight_scale` para fijar xcorr pico â‰ˆ **0.3â€“0.5**.
* [ ] AÃ±adir opciÃ³n de **probe dÃ©bil** en A (seno/step/chirp 5â€“10% de Ïƒ) para medir **ganancia/fase** vs. la distribuciÃ³n de delays.
* [ ] Implementar formalmente los **bloques CRN** en `sweep.py` y guardar artefactos por bloque (params, W\_intra/inter, spike trains, estados).
* [ ] Definir dos configs en `configs/`: **baseline simÃ©trico** y **masterâ†’slave** (una sola asimetrÃ­a a la vez).
* [ ] Establecer **warm-up â‰¥200â€“300 ms** y actualizar dashboards con PSTH/STA y ordenaciÃ³n por lag.

---

## ğŸ“š Referencias consultadas (si aplica)

* Izhikevich (2003) â€” dinÃ¡mica del modelo y heterogeneidad.
* Buenas prÃ¡cticas de **CRN** (common random numbers) y â€œfrozen noiseâ€ para reducciÃ³n de varianza en comparaciones simuladas.
* Literatura sobre **delays y sincronizaciÃ³n** (efecto de media y anchura en acoplamiento y coherencia).
