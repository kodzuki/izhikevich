{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Propagación de Spikes: Barrido 2D (K, rate_hz)\n",
    "\n",
    "## Objetivo\n",
    "\n",
    "Estudiar las probabilidades de activación de vecinos y el firing rate en función de:\n",
    "- **K (acoplamiento recurrente)**: Factor de escalado de pesos sinápticos\n",
    "- **rate_hz (input externo)**: Tasa de estímulo talámico\n",
    "\n",
    "## Estrategia\n",
    "\n",
    "1. **Barrido 2D**: Simular todas las combinaciones (K, rate_hz) → obtener (FR, P, σ)\n",
    "2. **Matching por FR**: Para cada (K≠0, FR_target), encontrar K=0 con FR≈FR_target\n",
    "3. **Contribución de red**: ΔP = P_coupled - P_baseline (mismo FR, diferente origen)\n",
    "4. **Visualización**: Heatmaps, cortes 1D, análisis de ΔP(K, FR)\n",
    "\n",
    "## Hipótesis\n",
    "\n",
    "- FR ≈ a·rate_hz (relación casi lineal)\n",
    "- K=0 define actividad espúrea (baseline)\n",
    "- ΔP(K>0) captura la dinámica de red pura\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup y Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# IMPORTS\n",
    "# =============================================================================\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Navegación al directorio raíz del proyecto\n",
    "if Path.cwd().name == 'notebooks':\n",
    "    os.chdir('..')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import seaborn as sns\n",
    "from brian2 import *\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "import pickle\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# Imports del proyecto\n",
    "from src.two_populations.model import IzhikevichNetwork\n",
    "from src.two_populations.metrics import analyze_simulation_results\n",
    "from src.two_populations.helpers.logger import setup_logger\n",
    "\n",
    "# Configurar logger\n",
    "logger = setup_logger(\n",
    "    experiment_name=\"spike_propagation_2d\",\n",
    "    console_level=\"INFO\",\n",
    "    file_level=\"DEBUG\",\n",
    "    log_to_file=False\n",
    ")\n",
    "\n",
    "logger.info(f\"Working directory: {Path.cwd()}\")\n",
    "logger.info(f\"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# Estilo de plots\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parámetros del Barrido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CONFIGURACIÓN DEL BARRIDO\n",
    "# =============================================================================\n",
    "\n",
    "# Tamaño de red\n",
    "Ne = 800\n",
    "Ni = 200\n",
    "\n",
    "# Parámetros de simulación\n",
    "SIM_CONFIG = {\n",
    "    'dt_ms': 0.1,\n",
    "    'T_ms': 3000,\n",
    "    'warmup_ms': 500\n",
    "}\n",
    "\n",
    "# Parámetros fijos de red\n",
    "NETWORK_PARAMS = {\n",
    "    'Ne': Ne,\n",
    "    'Ni': Ni,\n",
    "    'noise_exc': 0.884,\n",
    "    'noise_inh': 0.60,\n",
    "    'p_intra': 0.1,\n",
    "    'delay': 0.0,\n",
    "    'stim_start_ms': None,\n",
    "    'stim_duration_ms': SIM_CONFIG['T_ms'],\n",
    "    'stim_base': 1.0,\n",
    "    'stim_elevated': None\n",
    "}\n",
    "\n",
    "# Rango de parámetros a barrer\n",
    "K_VALUES = np.array([0.0, 0.5, 1.0, 1.5, 2.0, 2.5, 3.0, 3.5, 4.0, 5.0, 7.0, 10.0])\n",
    "RATE_HZ_VALUES = np.array([2, 3, 4, 5, 6, 7, 8, 10, 12, 15, 20])\n",
    "\n",
    "# Parámetros del análisis de propagación\n",
    "PROPAGATION_CONFIG = {\n",
    "    'window_ms': 5.0,         # Ventana temporal para detectar respuestas\n",
    "    'min_weight': 0.0,        # Peso mínimo para considerar conexión\n",
    "    'min_spikes': 20,         # Mínimo de spikes para incluir neurona\n",
    "}\n",
    "\n",
    "# Seeds\n",
    "FIXED_SEED = 100\n",
    "VARIABLE_SEED = 200\n",
    "\n",
    "# Directorio de salida\n",
    "OUTPUT_DIR = Path('results/spike_propagation_2d')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "logger.info(f\"Barrido configurado:\")\n",
    "logger.info(f\"  K values: {K_VALUES}\")\n",
    "logger.info(f\"  rate_hz values: {RATE_HZ_VALUES}\")\n",
    "logger.info(f\"  Total combinaciones: {len(K_VALUES) * len(RATE_HZ_VALUES)}\")\n",
    "logger.info(f\"  Simulación: {SIM_CONFIG['T_ms']}ms @ dt={SIM_CONFIG['dt_ms']}ms\")\n",
    "logger.info(f\"  Red: {Ne}E + {Ni}I, p_intra={NETWORK_PARAMS['p_intra']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clase de Análisis de Propagación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# PROPAGATION ANALYZER\n",
    "# =============================================================================\n",
    "\n",
    "class PropagationAnalyzer:\n",
    "    \"\"\"\n",
    "    Analiza propagación forward E→E:\n",
    "    Cuando neurona i dispara, ¿cuántos vecinos j responden en ventana temporal?\n",
    "    \n",
    "    Métricas:\n",
    "        - P_transmission: probabilidad de activar vecino por spike\n",
    "        - σ (sigma): branching ratio = <n_activados>\n",
    "        - firing_rate: tasa de disparo poblacional (Hz)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, window_ms=5.0, min_weight=0.0, min_spikes=20):\n",
    "        self.window = window_ms\n",
    "        self.min_weight = min_weight\n",
    "        self.min_spikes = min_spikes\n",
    "        \n",
    "    def extract_connectivity_E2E(self, synapses_intra, Ne, verbose=False):\n",
    "        \"\"\"\n",
    "        Extrae grafo de conectividad E→E desde sinapsis Brian2.\n",
    "        \n",
    "        Returns:\n",
    "            neighbors: dict {pre_idx: [post_idx_1, post_idx_2, ...]}\n",
    "            weights: dict {(pre, post): weight}\n",
    "        \"\"\"\n",
    "        neighbors = defaultdict(list)\n",
    "        weights = {}\n",
    "        \n",
    "        pre_indices = np.array(synapses_intra.i)\n",
    "        post_indices = np.array(synapses_intra.j)\n",
    "        syn_weights = np.array(synapses_intra.w)\n",
    "        \n",
    "        # Filtro: E→E con peso > threshold\n",
    "        E2E_mask = (pre_indices < Ne) & (post_indices < Ne) & (syn_weights >= 0.0)\n",
    "        mask = E2E_mask & (syn_weights >= self.min_weight)\n",
    "        \n",
    "        for pre, post, w in zip(pre_indices[mask], post_indices[mask], syn_weights[mask]):\n",
    "            neighbors[int(pre)].append(int(post))\n",
    "            weights[(int(pre), int(post))] = float(w)\n",
    "        \n",
    "        if verbose:\n",
    "            degrees = [len(v) for v in neighbors.values()]\n",
    "            logger.debug(f\"  E→E connections: {np.sum(mask)} (w>{self.min_weight})\")\n",
    "            logger.debug(f\"  Out-degree: mean={np.mean(degrees):.1f}, max={np.max(degrees)}\")\n",
    "        \n",
    "        return dict(neighbors), weights\n",
    "    \n",
    "    def organize_spike_times(self, spike_times_arr, spike_indices_arr):\n",
    "        \"\"\"\n",
    "        Organiza spikes por neurona.\n",
    "        \n",
    "        Returns:\n",
    "            spike_dict: {neuron_idx: sorted_spike_times_array}\n",
    "        \"\"\"\n",
    "        spike_dict = defaultdict(list)\n",
    "        \n",
    "        for t, idx in zip(spike_times_arr, spike_indices_arr):\n",
    "            spike_dict[int(idx)].append(float(t))\n",
    "        \n",
    "        spike_dict = {k: np.sort(v) for k, v in spike_dict.items()}\n",
    "        return dict(spike_dict)\n",
    "    \n",
    "    def count_responses_single_spike(self, pre_spike_time, post_neuron_spikes):\n",
    "        \"\"\"\n",
    "        Verifica si neurona post respondió en ventana [t, t+window).\n",
    "        \"\"\"\n",
    "        if len(post_neuron_spikes) == 0:\n",
    "            return False\n",
    "        \n",
    "        responses = post_neuron_spikes[\n",
    "            (post_neuron_spikes > pre_spike_time) & \n",
    "            (post_neuron_spikes < pre_spike_time + self.window)\n",
    "        ]\n",
    "        return len(responses) > 0\n",
    "    \n",
    "    def analyze(self, spike_dict, neighbors, T_total, warmup=0.0):\n",
    "        \"\"\"\n",
    "        Análisis principal de propagación.\n",
    "        \n",
    "        Args:\n",
    "            spike_dict: {neuron_idx: spike_times}\n",
    "            neighbors: {pre_idx: [post_idx_list]}\n",
    "            T_total: duración total (ms)\n",
    "            warmup: tiempo de warmup a excluir (ms)\n",
    "            \n",
    "        Returns:\n",
    "            dict con métricas: P_transmission, sigma, firing_rate, stats\n",
    "        \"\"\"\n",
    "        # Filtrar spikes por warmup\n",
    "        spike_dict_filtered = {\n",
    "            nid: times[times >= warmup] \n",
    "            for nid, times in spike_dict.items()\n",
    "        }\n",
    "        \n",
    "        T_analysis = T_total - warmup\n",
    "        \n",
    "        ratios_per_spike = []\n",
    "        activated_counts = []\n",
    "        per_neuron_stats = {}\n",
    "        \n",
    "        total_spikes_analyzed = 0\n",
    "        neurons_analyzed = 0\n",
    "        \n",
    "        for pre_idx in neighbors.keys():\n",
    "            if pre_idx not in spike_dict_filtered:\n",
    "                continue\n",
    "            \n",
    "            pre_spikes = spike_dict_filtered[pre_idx]\n",
    "            \n",
    "            if len(pre_spikes) < self.min_spikes:\n",
    "                continue\n",
    "            \n",
    "            post_neighbors = neighbors[pre_idx]\n",
    "            n_neighbors = len(post_neighbors)\n",
    "            \n",
    "            if n_neighbors == 0:\n",
    "                continue\n",
    "            \n",
    "            neuron_ratios = []\n",
    "            neuron_activated = []\n",
    "            \n",
    "            for spike_time in pre_spikes:\n",
    "                n_activated = 0\n",
    "                \n",
    "                for post_idx in post_neighbors:\n",
    "                    if post_idx not in spike_dict_filtered:\n",
    "                        continue\n",
    "                    \n",
    "                    post_spikes = spike_dict_filtered[post_idx]\n",
    "                    \n",
    "                    if self.count_responses_single_spike(spike_time, post_spikes):\n",
    "                        n_activated += 1\n",
    "                \n",
    "                ratio = n_activated / n_neighbors\n",
    "                \n",
    "                ratios_per_spike.append(ratio)\n",
    "                activated_counts.append(n_activated)\n",
    "                neuron_ratios.append(ratio)\n",
    "                neuron_activated.append(n_activated)\n",
    "                \n",
    "                total_spikes_analyzed += 1\n",
    "            \n",
    "            per_neuron_stats[pre_idx] = {\n",
    "                'n_spikes': len(pre_spikes),\n",
    "                'n_neighbors': n_neighbors,\n",
    "                'mean_ratio': np.mean(neuron_ratios),\n",
    "                'mean_activated': np.mean(neuron_activated)\n",
    "            }\n",
    "            neurons_analyzed += 1\n",
    "        \n",
    "        # Calcular firing rate poblacional\n",
    "        total_spikes = sum(len(times) for times in spike_dict_filtered.values())\n",
    "        n_neurons = len(spike_dict_filtered)\n",
    "        firing_rate = (total_spikes / n_neurons / T_analysis) * 1000.0  # Hz\n",
    "        \n",
    "        ratios_per_spike = np.array(ratios_per_spike)\n",
    "        activated_counts = np.array(activated_counts)\n",
    "        \n",
    "        results = {\n",
    "            'P_transmission': np.mean(ratios_per_spike) if len(ratios_per_spike) > 0 else 0.0,\n",
    "            'P_transmission_std': np.std(ratios_per_spike) if len(ratios_per_spike) > 0 else 0.0,\n",
    "            'sigma': np.mean(activated_counts) if len(activated_counts) > 0 else 0.0,\n",
    "            'sigma_std': np.std(activated_counts) if len(activated_counts) > 0 else 0.0,\n",
    "            'firing_rate': firing_rate,\n",
    "            'ratio_distribution': ratios_per_spike,\n",
    "            'activated_counts': activated_counts,\n",
    "            'per_neuron': per_neuron_stats,\n",
    "            'stats': {\n",
    "                'n_neurons_analyzed': neurons_analyzed,\n",
    "                'total_spikes_analyzed': total_spikes_analyzed,\n",
    "                'total_spikes': total_spikes,\n",
    "                'n_neurons_active': n_neurons,\n",
    "                'T_analysis': T_analysis\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        return results\n",
    "\n",
    "logger.success(\"PropagationAnalyzer class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Función de Simulación Parametrizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SIMULATION RUNNER\n",
    "# =============================================================================\n",
    "\n",
    "def run_single_simulation(k_factor, rate_hz, trial=0, verbose=False):\n",
    "    \"\"\"\n",
    "    Ejecuta una simulación con parámetros (k_factor, rate_hz).\n",
    "    \n",
    "    Args:\n",
    "        k_factor: Factor de acoplamiento recurrente\n",
    "        rate_hz: Tasa de estímulo externo (Hz)\n",
    "        trial: Índice de trial (para seeds)\n",
    "        verbose: Si True, imprime detalles\n",
    "        \n",
    "    Returns:\n",
    "        dict con:\n",
    "            - network: objeto IzhikevichNetwork\n",
    "            - results: resultados de simulación\n",
    "            - spike_dict: {neuron_idx: spike_times}\n",
    "            - neighbors: grafo de conectividad E→E\n",
    "            - weights: pesos sinápticos\n",
    "    \"\"\"\n",
    "    start_scope()\n",
    "    \n",
    "    # Crear red\n",
    "    network = IzhikevichNetwork(\n",
    "        dt_val=SIM_CONFIG['dt_ms'],\n",
    "        T_total=SIM_CONFIG['T_ms'],\n",
    "        fixed_seed=FIXED_SEED,\n",
    "        variable_seed=VARIABLE_SEED,\n",
    "        trial=trial\n",
    "    )\n",
    "    \n",
    "    # Parámetros de población\n",
    "    params = {\n",
    "        **NETWORK_PARAMS,\n",
    "        'k_exc': k_factor,\n",
    "        'k_inh': k_factor * 3.9,\n",
    "        'rate_hz': rate_hz\n",
    "    }\n",
    "    \n",
    "    # Crear población A\n",
    "    pop_A = network.create_population2(name='A', **params)\n",
    "    \n",
    "    # Setup monitors (no grabar voltajes para ahorrar memoria)\n",
    "    network.setup_monitors(['A'], record_v_dt=None, sample_fraction=0.0)\n",
    "    \n",
    "    # Ejecutar simulación\n",
    "    results = network.run_simulation()\n",
    "    \n",
    "    # Extraer conectividad\n",
    "    analyzer = PropagationAnalyzer(\n",
    "        window_ms=PROPAGATION_CONFIG['window_ms'],\n",
    "        min_weight=PROPAGATION_CONFIG['min_weight'],\n",
    "        min_spikes=PROPAGATION_CONFIG['min_spikes']\n",
    "    )\n",
    "    \n",
    "    neighbors, weights = analyzer.extract_connectivity_E2E(\n",
    "        network.populations['A']['syn_intra'],\n",
    "        Ne,\n",
    "        verbose=verbose\n",
    "    )\n",
    "    \n",
    "    # Organizar spikes\n",
    "    spike_dict = analyzer.organize_spike_times(\n",
    "        results['A']['spike_times'],\n",
    "        results['A']['spike_indices']\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        n_spikes = len(results['A']['spike_times'])\n",
    "        logger.info(f\"  Simulation completed: {n_spikes} spikes\")\n",
    "    \n",
    "    return {\n",
    "        'network': network,\n",
    "        'results': results,\n",
    "        'spike_dict': spike_dict,\n",
    "        'neighbors': neighbors,\n",
    "        'weights': weights\n",
    "    }\n",
    "\n",
    "logger.success(\"Simulation runner function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Barrido 2D: (K, rate_hz) → (FR, P, σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 2D SWEEP\n",
    "# =============================================================================\n",
    "\n",
    "def run_2d_sweep(K_values, rate_hz_values, save_results=True):\n",
    "    \"\"\"\n",
    "    Ejecuta barrido 2D completo.\n",
    "    \n",
    "    Args:\n",
    "        K_values: array de valores de K\n",
    "        rate_hz_values: array de valores de rate_hz\n",
    "        save_results: si True, guarda resultados en pickle\n",
    "        \n",
    "    Returns:\n",
    "        list of dicts con resultados de cada simulación\n",
    "    \"\"\"\n",
    "    results_list = []\n",
    "    total_sims = len(K_values) * len(rate_hz_values)\n",
    "    \n",
    "    logger.info(f\"Starting 2D sweep: {total_sims} simulations\")\n",
    "    logger.info(f\"K: {K_values}\")\n",
    "    logger.info(f\"rate_hz: {rate_hz_values}\")\n",
    "    \n",
    "    # Crear analyzer\n",
    "    analyzer = PropagationAnalyzer(\n",
    "        window_ms=PROPAGATION_CONFIG['window_ms'],\n",
    "        min_weight=PROPAGATION_CONFIG['min_weight'],\n",
    "        min_spikes=PROPAGATION_CONFIG['min_spikes']\n",
    "    )\n",
    "    \n",
    "    # Progress bar\n",
    "    with tqdm(total=total_sims, desc=\"2D Sweep\") as pbar:\n",
    "        for k_val in K_values:\n",
    "            for rate_val in rate_hz_values:\n",
    "                try:\n",
    "                    # Simular\n",
    "                    sim_data = run_single_simulation(\n",
    "                        k_factor=k_val,\n",
    "                        rate_hz=rate_val,\n",
    "                        trial=0,\n",
    "                        verbose=False\n",
    "                    )\n",
    "                    \n",
    "                    # Analizar propagación\n",
    "                    prop_results = analyzer.analyze(\n",
    "                        spike_dict=sim_data['spike_dict'],\n",
    "                        neighbors=sim_data['neighbors'],\n",
    "                        T_total=SIM_CONFIG['T_ms'],\n",
    "                        warmup=SIM_CONFIG['warmup_ms']\n",
    "                    )\n",
    "                    \n",
    "                    # Guardar resultados condensados\n",
    "                    result_entry = {\n",
    "                        'k': k_val,\n",
    "                        'rate_hz': rate_val,\n",
    "                        'firing_rate': prop_results['firing_rate'],\n",
    "                        'P_transmission': prop_results['P_transmission'],\n",
    "                        'P_transmission_std': prop_results['P_transmission_std'],\n",
    "                        'sigma': prop_results['sigma'],\n",
    "                        'sigma_std': prop_results['sigma_std'],\n",
    "                        'n_neurons_analyzed': prop_results['stats']['n_neurons_analyzed'],\n",
    "                        'total_spikes': prop_results['stats']['total_spikes']\n",
    "                    }\n",
    "                    \n",
    "                    results_list.append(result_entry)\n",
    "                    \n",
    "                    pbar.set_postfix({\n",
    "                        'K': f\"{k_val:.1f}\",\n",
    "                        'rate': f\"{rate_val:.0f}\",\n",
    "                        'FR': f\"{prop_results['firing_rate']:.1f}\",\n",
    "                        'P': f\"{prop_results['P_transmission']:.3f}\"\n",
    "                    })\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error at K={k_val}, rate={rate_val}: {str(e)}\")\n",
    "                    result_entry = {\n",
    "                        'k': k_val,\n",
    "                        'rate_hz': rate_val,\n",
    "                        'firing_rate': np.nan,\n",
    "                        'P_transmission': np.nan,\n",
    "                        'P_transmission_std': np.nan,\n",
    "                        'sigma': np.nan,\n",
    "                        'sigma_std': np.nan,\n",
    "                        'n_neurons_analyzed': 0,\n",
    "                        'total_spikes': 0\n",
    "                    }\n",
    "                    results_list.append(result_entry)\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    # Convertir a DataFrame\n",
    "    df_results = pd.DataFrame(results_list)\n",
    "    \n",
    "    # Guardar resultados\n",
    "    if save_results:\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        output_file = OUTPUT_DIR / f'sweep_2d_{timestamp}.pkl'\n",
    "        with open(output_file, 'wb') as f:\n",
    "            pickle.dump({\n",
    "                'df_results': df_results,\n",
    "                'K_values': K_values,\n",
    "                'rate_hz_values': rate_hz_values,\n",
    "                'config': {\n",
    "                    'SIM_CONFIG': SIM_CONFIG,\n",
    "                    'NETWORK_PARAMS': NETWORK_PARAMS,\n",
    "                    'PROPAGATION_CONFIG': PROPAGATION_CONFIG\n",
    "                }\n",
    "            }, f)\n",
    "        logger.success(f\"Results saved to {output_file}\")\n",
    "    \n",
    "    logger.success(f\"2D sweep completed: {len(df_results)} simulations\")\n",
    "    \n",
    "    return df_results\n",
    "\n",
    "logger.success(\"2D sweep function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EJECUTAR BARRIDO 2D\n",
    "# =============================================================================\n",
    "\n",
    "# NOTA: Este bloque tarda ~30-60 minutos dependiendo del hardware\n",
    "# Puedes comentar esta celda y cargar resultados previos en la siguiente sección\n",
    "\n",
    "logger.info(\"Starting 2D sweep...\")\n",
    "df_sweep = run_2d_sweep(K_VALUES, RATE_HZ_VALUES, save_results=True)\n",
    "\n",
    "# Mostrar resumen\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SWEEP SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(df_sweep.describe())\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cargar Resultados (Opcional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# LOAD PREVIOUS RESULTS (OPTIONAL)\n",
    "# =============================================================================\n",
    "\n",
    "# Si ya ejecutaste el barrido antes, puedes cargar los resultados:\n",
    "\n",
    "# load_file = OUTPUT_DIR / 'sweep_2d_YYYYMMDD_HHMMSS.pkl'  # <-- Editar con tu archivo\n",
    "# with open(load_file, 'rb') as f:\n",
    "#     loaded_data = pickle.load(f)\n",
    "# df_sweep = loaded_data['df_results']\n",
    "# logger.info(f\"Loaded results from {load_file}\")\n",
    "# print(df_sweep.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Análisis de Matching por FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# BASELINE MATCHING POR FIRING RATE\n",
    "# =============================================================================\n",
    "\n",
    "def compute_network_contribution(df_sweep):\n",
    "    \"\"\"\n",
    "    Calcula contribución de red mediante matching por FR.\n",
    "    \n",
    "    Para cada (K>0, FR_target):\n",
    "        1. Encontrar K=0 con FR ≈ FR_target\n",
    "        2. Calcular ΔP = P_coupled - P_baseline\n",
    "        3. Calcular Δσ = σ_coupled - σ_baseline\n",
    "    \n",
    "    Args:\n",
    "        df_sweep: DataFrame con resultados del barrido\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame con columnas adicionales: FR_baseline_matched, P_baseline, delta_P, delta_sigma\n",
    "    \"\"\"\n",
    "    # Separar baseline (K=0) y coupled (K>0)\n",
    "    df_baseline = df_sweep[df_sweep['k'] == 0.0].copy()\n",
    "    df_coupled = df_sweep[df_sweep['k'] > 0.0].copy()\n",
    "    \n",
    "    logger.info(f\"Baseline points: {len(df_baseline)}\")\n",
    "    logger.info(f\"Coupled points: {len(df_coupled)}\")\n",
    "    \n",
    "    # Crear interpolador para baseline: rate_hz → FR, P, σ\n",
    "    baseline_sorted = df_baseline.sort_values('rate_hz')\n",
    "    \n",
    "    interp_FR = interp1d(\n",
    "        baseline_sorted['rate_hz'],\n",
    "        baseline_sorted['firing_rate'],\n",
    "        kind='linear',\n",
    "        fill_value='extrapolate'\n",
    "    )\n",
    "    \n",
    "    interp_P = interp1d(\n",
    "        baseline_sorted['firing_rate'],\n",
    "        baseline_sorted['P_transmission'],\n",
    "        kind='linear',\n",
    "        fill_value='extrapolate'\n",
    "    )\n",
    "    \n",
    "    interp_sigma = interp1d(\n",
    "        baseline_sorted['firing_rate'],\n",
    "        baseline_sorted['sigma'],\n",
    "        kind='linear',\n",
    "        fill_value='extrapolate'\n",
    "    )\n",
    "    \n",
    "    # Para cada punto coupled, encontrar baseline con FR similar\n",
    "    matched_results = []\n",
    "    \n",
    "    for idx, row in df_coupled.iterrows():\n",
    "        FR_target = row['firing_rate']\n",
    "        \n",
    "        # Interpolar valores baseline para este FR\n",
    "        try:\n",
    "            P_baseline = float(interp_P(FR_target))\n",
    "            sigma_baseline = float(interp_sigma(FR_target))\n",
    "            \n",
    "            matched_results.append({\n",
    "                'k': row['k'],\n",
    "                'rate_hz': row['rate_hz'],\n",
    "                'firing_rate': FR_target,\n",
    "                'P_transmission': row['P_transmission'],\n",
    "                'sigma': row['sigma'],\n",
    "                'P_baseline': P_baseline,\n",
    "                'sigma_baseline': sigma_baseline,\n",
    "                'delta_P': row['P_transmission'] - P_baseline,\n",
    "                'delta_sigma': row['sigma'] - sigma_baseline,\n",
    "                'fold_change_P': row['P_transmission'] / P_baseline if P_baseline > 0 else np.nan,\n",
    "                'fold_change_sigma': row['sigma'] / sigma_baseline if sigma_baseline > 0 else np.nan\n",
    "            })\n",
    "        except Exception as e:\n",
    "            logger.warning(f\"Could not match K={row['k']}, rate={row['rate_hz']}: {e}\")\n",
    "    \n",
    "    df_matched = pd.DataFrame(matched_results)\n",
    "    \n",
    "    logger.success(f\"Matched {len(df_matched)} points\")\n",
    "    \n",
    "    return df_matched, df_baseline\n",
    "\n",
    "# Ejecutar matching\n",
    "df_network_contribution, df_baseline = compute_network_contribution(df_sweep)\n",
    "\n",
    "# Mostrar resumen\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NETWORK CONTRIBUTION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "print(df_network_contribution.groupby('k')[['delta_P', 'delta_sigma', 'fold_change_P']].mean())\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Visualizaciones: Heatmaps 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# HEATMAPS 2D: P(K, rate_hz), FR(K, rate_hz), σ(K, rate_hz)\n",
    "# =============================================================================\n",
    "\n",
    "def plot_2d_heatmaps(df_sweep, K_values, rate_hz_values):\n",
    "    \"\"\"\n",
    "    Genera heatmaps 2D de las métricas principales.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "    \n",
    "    # Preparar grillas\n",
    "    metrics = [\n",
    "        ('firing_rate', 'Firing Rate (Hz)', 'viridis'),\n",
    "        ('P_transmission', 'P_transmission', 'plasma'),\n",
    "        ('sigma', 'σ (branching ratio)', 'coolwarm')\n",
    "    ]\n",
    "    \n",
    "    for col_idx, (metric, title, cmap) in enumerate(metrics):\n",
    "        # Raw heatmap\n",
    "        ax = axes[0, col_idx]\n",
    "        \n",
    "        pivot = df_sweep.pivot_table(\n",
    "            index='k',\n",
    "            columns='rate_hz',\n",
    "            values=metric,\n",
    "            aggfunc='mean'\n",
    "        )\n",
    "        \n",
    "        im = ax.imshow(\n",
    "            pivot.values,\n",
    "            aspect='auto',\n",
    "            cmap=cmap,\n",
    "            origin='lower',\n",
    "            extent=[rate_hz_values.min(), rate_hz_values.max(), \n",
    "                   K_values.min(), K_values.max()]\n",
    "        )\n",
    "        \n",
    "        ax.set_xlabel('rate_hz (Hz)', fontsize=12)\n",
    "        ax.set_ylabel('K (coupling)', fontsize=12)\n",
    "        ax.set_title(f'{title}', fontsize=13, fontweight='bold')\n",
    "        plt.colorbar(im, ax=ax, label=title)\n",
    "        \n",
    "        # Smoothed heatmap\n",
    "        ax = axes[1, col_idx]\n",
    "        \n",
    "        smoothed = gaussian_filter(pivot.values, sigma=0.8)\n",
    "        \n",
    "        im = ax.imshow(\n",
    "            smoothed,\n",
    "            aspect='auto',\n",
    "            cmap=cmap,\n",
    "            origin='lower',\n",
    "            extent=[rate_hz_values.min(), rate_hz_values.max(), \n",
    "                   K_values.min(), K_values.max()]\n",
    "        )\n",
    "        \n",
    "        ax.set_xlabel('rate_hz (Hz)', fontsize=12)\n",
    "        ax.set_ylabel('K (coupling)', fontsize=12)\n",
    "        ax.set_title(f'{title} (smoothed)', fontsize=13, fontweight='bold')\n",
    "        plt.colorbar(im, ax=ax, label=title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generar heatmaps\n",
    "fig_heatmaps = plot_2d_heatmaps(df_sweep, K_VALUES, RATE_HZ_VALUES)\n",
    "plt.savefig(OUTPUT_DIR / 'heatmaps_2d.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "logger.success(\"Heatmaps generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Visualizaciones: Cortes 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CORTES 1D: P vs K (rate_hz fijo), P vs rate_hz (K fijo)\n",
    "# =============================================================================\n",
    "\n",
    "def plot_1d_slices(df_sweep, K_values, rate_hz_values):\n",
    "    \"\"\"\n",
    "    Genera cortes 1D de las métricas.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # === FILA 1: P_transmission ===\n",
    "    \n",
    "    # P vs K (varios rate_hz)\n",
    "    ax = axes[0, 0]\n",
    "    rate_hz_samples = [4, 8, 12, 20]\n",
    "    for rate in rate_hz_samples:\n",
    "        df_slice = df_sweep[df_sweep['rate_hz'] == rate]\n",
    "        ax.plot(df_slice['k'], df_slice['P_transmission'], \n",
    "               'o-', label=f'rate={rate}Hz', linewidth=2, markersize=6)\n",
    "    ax.set_xlabel('K (coupling)', fontsize=12)\n",
    "    ax.set_ylabel('P_transmission', fontsize=12)\n",
    "    ax.set_title('P_transmission vs K', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # P vs rate_hz (varios K)\n",
    "    ax = axes[0, 1]\n",
    "    K_samples = [0.0, 1.0, 2.5, 5.0, 10.0]\n",
    "    for k in K_samples:\n",
    "        df_slice = df_sweep[df_sweep['k'] == k]\n",
    "        ax.plot(df_slice['rate_hz'], df_slice['P_transmission'], \n",
    "               'o-', label=f'K={k}', linewidth=2, markersize=6)\n",
    "    ax.set_xlabel('rate_hz (Hz)', fontsize=12)\n",
    "    ax.set_ylabel('P_transmission', fontsize=12)\n",
    "    ax.set_title('P_transmission vs rate_hz', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # σ vs K\n",
    "    ax = axes[0, 2]\n",
    "    for rate in rate_hz_samples:\n",
    "        df_slice = df_sweep[df_sweep['rate_hz'] == rate]\n",
    "        ax.plot(df_slice['k'], df_slice['sigma'], \n",
    "               'o-', label=f'rate={rate}Hz', linewidth=2, markersize=6)\n",
    "    ax.axhline(1.0, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Critical (σ=1)')\n",
    "    ax.set_xlabel('K (coupling)', fontsize=12)\n",
    "    ax.set_ylabel('σ (branching ratio)', fontsize=12)\n",
    "    ax.set_title('σ vs K', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # === FILA 2: Firing Rate ===\n",
    "    \n",
    "    # FR vs K\n",
    "    ax = axes[1, 0]\n",
    "    for rate in rate_hz_samples:\n",
    "        df_slice = df_sweep[df_sweep['rate_hz'] == rate]\n",
    "        ax.plot(df_slice['k'], df_slice['firing_rate'], \n",
    "               'o-', label=f'rate={rate}Hz', linewidth=2, markersize=6)\n",
    "    ax.set_xlabel('K (coupling)', fontsize=12)\n",
    "    ax.set_ylabel('Firing Rate (Hz)', fontsize=12)\n",
    "    ax.set_title('Firing Rate vs K', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # FR vs rate_hz\n",
    "    ax = axes[1, 1]\n",
    "    for k in K_samples:\n",
    "        df_slice = df_sweep[df_sweep['k'] == k]\n",
    "        ax.plot(df_slice['rate_hz'], df_slice['firing_rate'], \n",
    "               'o-', label=f'K={k}', linewidth=2, markersize=6)\n",
    "    ax.set_xlabel('rate_hz (Hz)', fontsize=12)\n",
    "    ax.set_ylabel('Firing Rate (Hz)', fontsize=12)\n",
    "    ax.set_title('Firing Rate vs rate_hz', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # FR vs rate_hz (linealidad)\n",
    "    ax = axes[1, 2]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(K_samples)))\n",
    "    for idx, k in enumerate(K_samples):\n",
    "        df_slice = df_sweep[df_sweep['k'] == k]\n",
    "        ax.scatter(df_slice['rate_hz'], df_slice['firing_rate'], \n",
    "                  label=f'K={k}', s=80, alpha=0.7, color=colors[idx])\n",
    "        # Fit lineal\n",
    "        if len(df_slice) > 2:\n",
    "            z = np.polyfit(df_slice['rate_hz'], df_slice['firing_rate'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            ax.plot(df_slice['rate_hz'], p(df_slice['rate_hz']), \n",
    "                   '--', color=colors[idx], linewidth=1.5, alpha=0.5)\n",
    "    ax.set_xlabel('rate_hz (Hz)', fontsize=12)\n",
    "    ax.set_ylabel('Firing Rate (Hz)', fontsize=12)\n",
    "    ax.set_title('FR ≈ a·rate_hz (linearity check)', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=9, loc='upper left')\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generar cortes 1D\n",
    "fig_slices = plot_1d_slices(df_sweep, K_VALUES, RATE_HZ_VALUES)\n",
    "plt.savefig(OUTPUT_DIR / 'slices_1d.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "logger.success(\"1D slices generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Análisis de Contribución de Red: ΔP, Δσ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# NETWORK CONTRIBUTION VISUALIZATION\n",
    "# =============================================================================\n",
    "\n",
    "def plot_network_contribution(df_matched, df_baseline):\n",
    "    \"\"\"\n",
    "    Visualiza la contribución de red (ΔP, Δσ).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # === FILA 1: ΔP ===\n",
    "    \n",
    "    # ΔP vs K\n",
    "    ax = axes[0, 0]\n",
    "    df_grouped = df_matched.groupby('k')['delta_P'].agg(['mean', 'std'])\n",
    "    ax.errorbar(df_grouped.index, df_grouped['mean'], yerr=df_grouped['std'],\n",
    "               fmt='o-', linewidth=2, markersize=8, capsize=5, capthick=2)\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "    ax.set_xlabel('K (coupling)', fontsize=12)\n",
    "    ax.set_ylabel('ΔP = P_coupled - P_baseline', fontsize=12)\n",
    "    ax.set_title('Network Contribution to P', fontsize=13, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # ΔP vs FR\n",
    "    ax = axes[0, 1]\n",
    "    K_samples = [1.0, 2.5, 5.0, 10.0]\n",
    "    for k in K_samples:\n",
    "        df_k = df_matched[df_matched['k'] == k]\n",
    "        ax.scatter(df_k['firing_rate'], df_k['delta_P'], \n",
    "                  label=f'K={k}', s=80, alpha=0.7)\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "    ax.set_xlabel('Firing Rate (Hz)', fontsize=12)\n",
    "    ax.set_ylabel('ΔP', fontsize=12)\n",
    "    ax.set_title('ΔP vs Firing Rate', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Fold change P\n",
    "    ax = axes[0, 2]\n",
    "    df_grouped = df_matched.groupby('k')['fold_change_P'].agg(['mean', 'std'])\n",
    "    ax.errorbar(df_grouped.index, df_grouped['mean'], yerr=df_grouped['std'],\n",
    "               fmt='o-', linewidth=2, markersize=8, capsize=5, capthick=2, color='purple')\n",
    "    ax.axhline(1.0, color='red', linestyle='--', linewidth=1.5, alpha=0.5, label='No change')\n",
    "    ax.set_xlabel('K (coupling)', fontsize=12)\n",
    "    ax.set_ylabel('Fold Change = P_coupled / P_baseline', fontsize=12)\n",
    "    ax.set_title('P Fold Change', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # === FILA 2: Δσ ===\n",
    "    \n",
    "    # Δσ vs K\n",
    "    ax = axes[1, 0]\n",
    "    df_grouped = df_matched.groupby('k')['delta_sigma'].agg(['mean', 'std'])\n",
    "    ax.errorbar(df_grouped.index, df_grouped['mean'], yerr=df_grouped['std'],\n",
    "               fmt='o-', linewidth=2, markersize=8, capsize=5, capthick=2, color='orange')\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "    ax.set_xlabel('K (coupling)', fontsize=12)\n",
    "    ax.set_ylabel('Δσ = σ_coupled - σ_baseline', fontsize=12)\n",
    "    ax.set_title('Network Contribution to σ', fontsize=13, fontweight='bold')\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Δσ vs FR\n",
    "    ax = axes[1, 1]\n",
    "    for k in K_samples:\n",
    "        df_k = df_matched[df_matched['k'] == k]\n",
    "        ax.scatter(df_k['firing_rate'], df_k['delta_sigma'], \n",
    "                  label=f'K={k}', s=80, alpha=0.7)\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=1.5, alpha=0.5)\n",
    "    ax.set_xlabel('Firing Rate (Hz)', fontsize=12)\n",
    "    ax.set_ylabel('Δσ', fontsize=12)\n",
    "    ax.set_title('Δσ vs Firing Rate', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    # Baseline vs Coupled scatter\n",
    "    ax = axes[1, 2]\n",
    "    colors = plt.cm.plasma(np.linspace(0, 1, len(K_samples)))\n",
    "    for idx, k in enumerate(K_samples):\n",
    "        df_k = df_matched[df_matched['k'] == k]\n",
    "        ax.scatter(df_k['P_baseline'], df_k['P_transmission'],\n",
    "                  label=f'K={k}', s=80, alpha=0.7, color=colors[idx])\n",
    "    # Diagonal\n",
    "    lims = [0, max(df_matched['P_baseline'].max(), df_matched['P_transmission'].max())]\n",
    "    ax.plot(lims, lims, 'k--', linewidth=1.5, alpha=0.5, label='P_coupled = P_baseline')\n",
    "    ax.set_xlabel('P_baseline (K=0)', fontsize=12)\n",
    "    ax.set_ylabel('P_coupled (K>0)', fontsize=12)\n",
    "    ax.set_title('P: Coupled vs Baseline', fontsize=13, fontweight='bold')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generar plots de contribución\n",
    "fig_contribution = plot_network_contribution(df_network_contribution, df_baseline)\n",
    "plt.savefig(OUTPUT_DIR / 'network_contribution.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "logger.success(\"Network contribution plots generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Tabla de Resultados Clave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# SUMMARY TABLE\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"SUMMARY: BASELINE (K=0) vs COUPLED (K>0)\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Baseline\n",
    "df_baseline_summary = df_baseline.describe()[['firing_rate', 'P_transmission', 'sigma']]\n",
    "print(\"\\nBASELINE (K=0):\")\n",
    "print(df_baseline_summary)\n",
    "\n",
    "# Coupled (promedio por K)\n",
    "df_coupled = df_sweep[df_sweep['k'] > 0.0]\n",
    "df_coupled_summary = df_coupled.groupby('k')[['firing_rate', 'P_transmission', 'sigma']].mean()\n",
    "print(\"\\nCOUPLED (K>0) - MEAN BY K:\")\n",
    "print(df_coupled_summary)\n",
    "\n",
    "# Network contribution\n",
    "df_contribution_summary = df_network_contribution.groupby('k')[['delta_P', 'delta_sigma', 'fold_change_P']].mean()\n",
    "print(\"\\nNETWORK CONTRIBUTION - MEAN BY K:\")\n",
    "print(df_contribution_summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "\n",
    "# Guardar tabla\n",
    "df_contribution_summary.to_csv(OUTPUT_DIR / 'network_contribution_summary.csv')\n",
    "logger.success(f\"Summary table saved to {OUTPUT_DIR / 'network_contribution_summary.csv'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Conclusiones y Próximos Pasos\n",
    "\n",
    "### Resultados esperados:\n",
    "\n",
    "1. **FR ≈ a·rate_hz**: Verificar linealidad entre input externo y firing rate\n",
    "2. **P(K, rate_hz)**: Probabilidad de transmisión aumenta con K\n",
    "3. **ΔP > 0 para K>0**: La red contribuye positivamente a la propagación\n",
    "4. **σ(K) → 1**: Transición hacia criticalidad con acoplamiento óptimo\n",
    "\n",
    "### Análisis complementarios:\n",
    "\n",
    "- [ ] Barrido con delays (τ ≠ 0)\n",
    "- [ ] Análisis de distribuciones de ISI\n",
    "- [ ] Separación E/I en la propagación\n",
    "- [ ] Correlación con INT\n",
    "- [ ] Análisis de criticalidad (avalanchas)\n",
    "\n",
    "### Optimizaciones:\n",
    "\n",
    "- [ ] Paralelizar simulaciones (múltiples trials)\n",
    "- [ ] Reducir resolución temporal en análisis\n",
    "- [ ] Guardar solo métricas (no raster completo)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
