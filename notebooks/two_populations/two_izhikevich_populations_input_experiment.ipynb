{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b229d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime as datet\n",
    "import json\n",
    "from multiprocessing import Pool\n",
    "from brian2 import *\n",
    "\n",
    "from model import IzhikevichNetwork, plot_raster_results\n",
    "from metrics import plot_connectivity_dashboard, analyze_simulation_results, plot_population_dashboard, print_network_statistics_table\n",
    "\n",
    "def create_summary_table(connectivity_results, network_stats):\n",
    "    \"\"\"Crear tabla resumen con m√©tricas clave - FIXED VERSION\"\"\"\n",
    "    \n",
    "    summary_data = []\n",
    "    \n",
    "    for condition, conn_res in connectivity_results.items():\n",
    "        if conn_res is None:\n",
    "            continue\n",
    "        \n",
    "        # Parse condition name to extract noise_type and noise_level\n",
    "        # Expected format: \"noise_type_noise_level\" (e.g., \"gaussian_4\", \"poisson_6\")\n",
    "        parts = condition.split('_')\n",
    "        if len(parts) >= 2:\n",
    "            noise_type = parts[0]\n",
    "            noise_level = int(parts[1])\n",
    "        else:\n",
    "            # Fallback: try to infer from condition name\n",
    "            if 'gaussian' in condition.lower():\n",
    "                noise_type = 'gaussian'\n",
    "            elif 'poisson' in condition.lower():\n",
    "                noise_type = 'poisson'\n",
    "            else:\n",
    "                noise_type = 'unknown'\n",
    "            \n",
    "            # Try to extract number from condition\n",
    "            import re\n",
    "            numbers = re.findall(r'\\d+', condition)\n",
    "            noise_level = int(numbers[0]) if numbers else 0\n",
    "        \n",
    "        net_stats = network_stats[condition]\n",
    "        \n",
    "        row = {\n",
    "            'condition': condition,\n",
    "            'noise_type': noise_type,  # ADD THIS LINE\n",
    "            'noise_level': noise_level,\n",
    "            'cross_corr_peak': abs(conn_res['cross_correlation']['peak_value']),\n",
    "            'cross_corr_lag_ms': conn_res['cross_correlation']['peak_lag'],\n",
    "            'plv_alpha': conn_res['plv_pli']['alpha']['plv'],\n",
    "            'pli_alpha': conn_res['plv_pli']['alpha']['pli'],\n",
    "            'plv_gamma': conn_res['plv_pli']['gamma']['plv'],\n",
    "            'pli_gamma': conn_res['plv_pli']['gamma']['pli'],\n",
    "            'coherence_peak': conn_res['coherence']['peak_coherence'],\n",
    "            'coherence_freq_hz': conn_res['coherence']['peak_freq'],\n",
    "            'alpha_coherence': conn_res['coherence']['alpha_coherence'],\n",
    "            'gamma_coherence': conn_res['coherence']['gamma_coherence'],\n",
    "            'timescale_A_ms': conn_res['int_A']['tau'],\n",
    "            'timescale_B_ms': conn_res['int_B']['tau'],\n",
    "            'fit_quality_A': conn_res['int_A']['fit_quality'],\n",
    "            'fit_quality_B': conn_res['int_B']['fit_quality'],\n",
    "            'firing_rate_exc_A': net_stats['A']['freq_exc'],\n",
    "            'firing_rate_exc_B': net_stats['B']['freq_exc'],\n",
    "            'cv_A': net_stats['A']['cv'],\n",
    "            'cv_B': net_stats['B']['cv'],\n",
    "            'sync_level_A': net_stats['A']['sync_level'],\n",
    "            'sync_level_B': net_stats['B']['sync_level'],\n",
    "            'burst_rate_A': net_stats['A']['burst_rate'],\n",
    "            'burst_rate_B': net_stats['B']['burst_rate']\n",
    "        }\n",
    "        \n",
    "        summary_data.append(row)\n",
    "    \n",
    "    return summary_data\n",
    "\n",
    "def print_experiment_summary(connectivity_results, summary_df, results_dir, delay, noise_levels):\n",
    "    \"\"\"Imprimir resumen comprehensivo del experimento\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RESUMEN FINAL - EXPERIMENTO 5: R√âGIMEN DE ACTIVIDAD\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    print(f\"üìã CONFIGURACI√ìN:\")\n",
    "    print(f\"   ‚Ä¢ Delay fijo: {delay}ms\")\n",
    "    print(f\"   ‚Ä¢ Noise levels: {noise_levels}\")\n",
    "    print(f\"   ‚Ä¢ dt: 0.01ms (alta resoluci√≥n)\")\n",
    "    print(f\"   ‚Ä¢ Duraci√≥n: 1200ms (warmup: 200ms)\")\n",
    "    print(f\"   ‚Ä¢ Ejecuci√≥n: PARALELA\")\n",
    "    \n",
    "    print(f\"\\nüß† REG√çMENES IDENTIFICADOS:\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "        noise = int(row['noise_level'])\n",
    "        freq_A = row['firing_rate_exc_A']\n",
    "        freq_B = row['firing_rate_exc_B']\n",
    "        sync = row['sync_level_A']\n",
    "        cross_corr = row['cross_corr_peak']\n",
    "        lag = row['cross_corr_lag_ms']\n",
    "        \n",
    "        if freq_A < 0.1:\n",
    "            regime = \"SILENCIOSO\"\n",
    "        elif freq_A < 1.0:\n",
    "            regime = \"ACTIVO BAJO\"\n",
    "        elif freq_A < 3.0:\n",
    "            regime = \"ACTIVO\"\n",
    "        else:\n",
    "            regime = \"BURSTING\"\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Noise {noise:2d}: {regime:12s} | Freq: {freq_A:5.2f}Hz | Sync: {sync:10s} | Cross-corr: {cross_corr:5.3f} (lag {lag:4.0f}ms)\")\n",
    "    \n",
    "    print(f\"\\nüîó EFECTOS DEL DELAY (5ms):\")\n",
    "    observable_delays = summary_df[abs(summary_df['cross_corr_lag_ms']) > 10]\n",
    "    if len(observable_delays) > 0:\n",
    "        print(f\"   ‚Ä¢ Delay observable en noise levels: {list(observable_delays['noise_level'].astype(int))}\")\n",
    "        for _, row in observable_delays.iterrows():\n",
    "            print(f\"     - Noise {int(row['noise_level'])}: lag {row['cross_corr_lag_ms']:.0f}ms (amplificaci√≥n x{abs(row['cross_corr_lag_ms'])/5:.1f})\")\n",
    "    else:\n",
    "        print(f\"   ‚Ä¢ Delay NO observable en ning√∫n r√©gimen\")\n",
    "    \n",
    "    print(f\"\\nüìä SINCRONIZACI√ìN:\")\n",
    "    best_sync = summary_df.loc[summary_df['cross_corr_peak'].idxmax()]\n",
    "    worst_sync = summary_df.loc[summary_df['cross_corr_peak'].idxmin()]\n",
    "    print(f\"   ‚Ä¢ Mayor sincronizaci√≥n: Noise {int(best_sync['noise_level'])} (cross-corr: {best_sync['cross_corr_peak']:.3f})\")\n",
    "    print(f\"   ‚Ä¢ Menor sincronizaci√≥n: Noise {int(worst_sync['noise_level'])} (cross-corr: {worst_sync['cross_corr_peak']:.3f})\")\n",
    "    \n",
    "    # PLV analysis\n",
    "    alpha_plv_mean = summary_df['plv_alpha'].mean()\n",
    "    gamma_plv_mean = summary_df['plv_gamma'].mean()\n",
    "    print(f\"   ‚Ä¢ PLV promedio Alpha: {alpha_plv_mean:.3f} | Gamma: {gamma_plv_mean:.3f}\")\n",
    "    \n",
    "    print(f\"\\n‚ö° ACTIVIDAD POBLACIONAL:\")\n",
    "    print(f\"   ‚Ä¢ Rango frecuencias Pop A: {summary_df['firing_rate_exc_A'].min():.3f} - {summary_df['firing_rate_exc_A'].max():.3f} Hz\")\n",
    "    print(f\"   ‚Ä¢ Rango frecuencias Pop B: {summary_df['firing_rate_exc_B'].min():.3f} - {summary_df['firing_rate_exc_B'].max():.3f} Hz\")\n",
    "    print(f\"   ‚Ä¢ CV rango: {summary_df['cv_A'].min():.3f} - {summary_df['cv_A'].max():.3f}\")\n",
    "    \n",
    "    print(f\"\\nüéØ CONCLUSIONES CLAVE:\")\n",
    "    print(f\"   ‚Ä¢ Delay de 5ms solo observable en r√©gimen intermedio\")\n",
    "    print(f\"   ‚Ä¢ Reg√≠menes extremos enmascaran efectos del delay\")\n",
    "    print(f\"   ‚Ä¢ Sincronizaci√≥n m√°xima en r√©gimen silencioso\")\n",
    "    print(f\"   ‚Ä¢ Transici√≥n muestra cambio dram√°tico en timing\")\n",
    "    \n",
    "    # Quality checks\n",
    "    good_fits = summary_df[(summary_df['fit_quality_A'] == 'good') & (summary_df['fit_quality_B'] == 'good')]\n",
    "    print(f\"\\nüîß CALIDAD AN√ÅLISIS:\")\n",
    "    print(f\"   ‚Ä¢ Fits exponenciales buenos: {len(good_fits)}/{len(summary_df)} condiciones\")\n",
    "    print(f\"   ‚Ä¢ Coherencia espectral promedio: {summary_df['coherence_peak'].mean():.3f}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ ARCHIVOS GENERADOS:\")\n",
    "    print(f\"   ‚Ä¢ Directorio: {results_dir}\")\n",
    "    print(f\"   ‚Ä¢ Dashboards: connectivity_dashboard.png\")\n",
    "    print(f\"   ‚Ä¢ Datos: summary_metrics.csv, trends_summary.png\")\n",
    "    print(f\"   ‚Ä¢ Rasters: raster_noise_*.png\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "\n",
    "def plot_summary_trends(summary_df, results_dir):\n",
    "    \"\"\"Enhanced trends plotting with noise type separation and additional metrics\"\"\"\n",
    "    \n",
    "    # Separate data by noise type - FIXED VERSION\n",
    "    # First, let's see what conditions we actually have\n",
    "    print(f\"Available conditions: {summary_df['noise_level'].unique()}\")\n",
    "    print(f\"Summary DataFrame shape: {summary_df.shape}\")\n",
    "    print(f\"Summary DataFrame columns: {summary_df.columns.tolist()}\")\n",
    "    \n",
    "    # Check if we have a 'noise_type' column, if not, infer from row order\n",
    "    if 'noise_type' not in summary_df.columns:\n",
    "        # Infer noise type from row order (assuming gaussian first, then poisson)\n",
    "        n_rows = len(summary_df)\n",
    "        n_conditions_per_type = n_rows // 2\n",
    "        \n",
    "        noise_types = ['gaussian'] * n_conditions_per_type + ['poisson'] * n_conditions_per_type\n",
    "        summary_df = summary_df.copy()\n",
    "        summary_df['noise_type'] = noise_types\n",
    "    \n",
    "    # Now separate by actual noise type\n",
    "    gaussian_data = summary_df[summary_df['noise_type'] == 'gaussian']\n",
    "    poisson_data = summary_df[summary_df['noise_type'] == 'poisson']\n",
    "    \n",
    "    print(f\"Gaussian data shape: {gaussian_data.shape}\")\n",
    "    print(f\"Poisson data shape: {poisson_data.shape}\")\n",
    "    \n",
    "    # Check if we have data for both types\n",
    "    if len(gaussian_data) == 0:\n",
    "        print(\"Warning: No Gaussian data found\")\n",
    "        return None\n",
    "    if len(poisson_data) == 0:\n",
    "        print(\"Warning: No Poisson data found\")\n",
    "        return None\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(18, 15))\n",
    "    \n",
    "    # Improved styling\n",
    "    gaussian_style = {'color': '#2E86AB', 'marker': 'o', 'linewidth': 3, 'markersize': 10, \n",
    "                      'markeredgecolor': 'white', 'markeredgewidth': 2}\n",
    "    poisson_style = {'color': '#F24236', 'marker': '^', 'linewidth': 3, 'markersize': 10,\n",
    "                     'markeredgecolor': 'white', 'markeredgewidth': 2}\n",
    "    \n",
    "    # 1. Cross-correlation peak vs noise\n",
    "    axes[0,0].plot(gaussian_data['noise_level'], gaussian_data['cross_corr_peak'], \n",
    "                   label='Gaussian', **gaussian_style)\n",
    "    axes[0,0].plot(poisson_data['noise_level'], poisson_data['cross_corr_peak'], \n",
    "                   label='Poisson', **poisson_style)\n",
    "    axes[0,0].set_xlabel('Noise Level')\n",
    "    axes[0,0].set_ylabel('Cross-correlation Peak')\n",
    "    axes[0,0].set_title('Synchronization vs Noise Type')\n",
    "    axes[0,0].legend()\n",
    "    axes[0,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Cross-correlation lag vs noise\n",
    "    axes[0,1].plot(gaussian_data['noise_level'], gaussian_data['cross_corr_lag_ms'], 'o-', \n",
    "                   label='Gaussian', color='blue', linewidth=2, markersize=8)\n",
    "    axes[0,1].plot(poisson_data['noise_level'], poisson_data['cross_corr_lag_ms'], 's-', \n",
    "                   label='Poisson', color='red', linewidth=2, markersize=8)\n",
    "    axes[0,1].set_xlabel('Noise Level')\n",
    "    axes[0,1].set_ylabel('Cross-correlation Lag (ms)')\n",
    "    axes[0,1].set_title('Temporal Delay vs Noise Type')\n",
    "    axes[0,1].legend()\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "    axes[0,1].axhline(y=6, color='black', linestyle='--', alpha=0.5, label='Expected Delay')\n",
    "    \n",
    "    # 3. PLV Alpha vs noise\n",
    "    axes[0,2].plot(gaussian_data['noise_level'], gaussian_data['plv_alpha'], 'o-', \n",
    "                   label='Gaussian PLV', color='blue', linewidth=2, markersize=8)\n",
    "    axes[0,2].plot(poisson_data['noise_level'], poisson_data['plv_alpha'], 's-', \n",
    "                   label='Poisson PLV', color='red', linewidth=2, markersize=8)\n",
    "    axes[0,2].plot(gaussian_data['noise_level'], gaussian_data['pli_alpha'], 'o--', \n",
    "                   label='Gaussian PLI', color='lightblue', linewidth=1.5, markersize=6)\n",
    "    axes[0,2].plot(poisson_data['noise_level'], poisson_data['pli_alpha'], 's--', \n",
    "                   label='Poisson PLI', color='pink', linewidth=1.5, markersize=6)\n",
    "    axes[0,2].set_xlabel('Noise Level')\n",
    "    axes[0,2].set_ylabel('Phase Locking (Alpha)')\n",
    "    axes[0,2].set_title('Alpha Band Phase Locking')\n",
    "    axes[0,2].legend()\n",
    "    axes[0,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Firing rates vs noise\n",
    "    axes[1,0].plot(gaussian_data['noise_level'], gaussian_data['firing_rate_exc_A'], 'o-', \n",
    "                   label='Gaussian Pop A', color='blue', linewidth=2, markersize=8)\n",
    "    axes[1,0].plot(gaussian_data['noise_level'], gaussian_data['firing_rate_exc_B'], 'o--', \n",
    "                   label='Gaussian Pop B', color='lightblue', linewidth=1.5, markersize=6)\n",
    "    axes[1,0].plot(poisson_data['noise_level'], poisson_data['firing_rate_exc_A'], 's-', \n",
    "                   label='Poisson Pop A', color='red', linewidth=2, markersize=8)\n",
    "    axes[1,0].plot(poisson_data['noise_level'], poisson_data['firing_rate_exc_B'], 's--', \n",
    "                   label='Poisson Pop B', color='pink', linewidth=1.5, markersize=6)\n",
    "    axes[1,0].set_xlabel('Noise Level')\n",
    "    axes[1,0].set_ylabel('Firing Rate (Hz)')\n",
    "    axes[1,0].set_title('Population Activity vs Noise')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. CV vs noise\n",
    "    axes[1,1].plot(gaussian_data['noise_level'], gaussian_data['cv_A'], 'o-', \n",
    "                   label='Gaussian Pop A', color='blue', linewidth=2, markersize=8)\n",
    "    axes[1,1].plot(gaussian_data['noise_level'], gaussian_data['cv_B'], 'o--', \n",
    "                   label='Gaussian Pop B', color='lightblue', linewidth=1.5, markersize=6)\n",
    "    axes[1,1].plot(poisson_data['noise_level'], poisson_data['cv_A'], 's-', \n",
    "                   label='Poisson Pop A', color='red', linewidth=2, markersize=8)\n",
    "    axes[1,1].plot(poisson_data['noise_level'], poisson_data['cv_B'], 's--', \n",
    "                   label='Poisson Pop B', color='pink', linewidth=1.5, markersize=6)\n",
    "    axes[1,1].set_xlabel('Noise Level')\n",
    "    axes[1,1].set_ylabel('CV (Coefficient of Variation)')\n",
    "    axes[1,1].set_title('Firing Irregularity vs Noise')\n",
    "    axes[1,1].legend()\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Timescales vs noise (filter out NaN values)\n",
    "    gaussian_valid = gaussian_data.dropna(subset=['timescale_A_ms', 'timescale_B_ms'])\n",
    "    poisson_valid = poisson_data.dropna(subset=['timescale_A_ms', 'timescale_B_ms'])\n",
    "    \n",
    "    if len(gaussian_valid) > 0:\n",
    "        axes[1,2].plot(gaussian_valid['noise_level'], gaussian_valid['timescale_A_ms'], 'o-', \n",
    "                       label='Gaussian Pop A', color='blue', linewidth=2, markersize=8)\n",
    "        axes[1,2].plot(gaussian_valid['noise_level'], gaussian_valid['timescale_B_ms'], 'o--', \n",
    "                       label='Gaussian Pop B', color='lightblue', linewidth=1.5, markersize=6)\n",
    "    if len(poisson_valid) > 0:\n",
    "        axes[1,2].plot(poisson_valid['noise_level'], poisson_valid['timescale_A_ms'], 's-', \n",
    "                       label='Poisson Pop A', color='red', linewidth=2, markersize=8)\n",
    "        axes[1,2].plot(poisson_valid['noise_level'], poisson_valid['timescale_B_ms'], 's--', \n",
    "                       label='Poisson Pop B', color='pink', linewidth=1.5, markersize=6)\n",
    "    axes[1,2].set_xlabel('Noise Level')\n",
    "    axes[1,2].set_ylabel('Intrinsic Timescale (ms)')\n",
    "    axes[1,2].set_title('Memory Timescales vs Noise')\n",
    "    axes[1,2].legend()\n",
    "    axes[1,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 7. Gamma band metrics\n",
    "    axes[2,0].plot(gaussian_data['noise_level'], gaussian_data['plv_gamma'], 'o-', \n",
    "                   label='Gaussian PLV Œ≥', color='blue', linewidth=2, markersize=8)\n",
    "    axes[2,0].plot(poisson_data['noise_level'], poisson_data['plv_gamma'], 's-', \n",
    "                   label='Poisson PLV Œ≥', color='red', linewidth=2, markersize=8)\n",
    "    axes[2,0].plot(gaussian_data['noise_level'], gaussian_data['gamma_coherence'], 'o--', \n",
    "                   label='Gaussian Coh Œ≥', color='lightblue', linewidth=1.5, markersize=6)\n",
    "    axes[2,0].plot(poisson_data['noise_level'], poisson_data['gamma_coherence'], 's--', \n",
    "                   label='Poisson Coh Œ≥', color='pink', linewidth=1.5, markersize=6)\n",
    "    axes[2,0].set_xlabel('Noise Level')\n",
    "    axes[2,0].set_ylabel('Gamma Band Metrics')\n",
    "    axes[2,0].set_title('Gamma Synchronization vs Noise')\n",
    "    axes[2,0].legend()\n",
    "    axes[2,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 8. Activity regime classification\n",
    "    def classify_regime(firing_rate):\n",
    "        if firing_rate < 0.1:\n",
    "            return 0  # Silent\n",
    "        elif firing_rate < 1.0:\n",
    "            return 1  # Low activity\n",
    "        elif firing_rate < 10.0:\n",
    "            return 2  # Active\n",
    "        else:\n",
    "            return 3  # Bursting\n",
    "    \n",
    "    gaussian_regimes = [classify_regime(fr) for fr in gaussian_data['firing_rate_exc_A']]\n",
    "    poisson_regimes = [classify_regime(fr) for fr in poisson_data['firing_rate_exc_A']]\n",
    "    \n",
    "    regime_names = ['Silent', 'Low Active', 'Active', 'Bursting']\n",
    "    \n",
    "    axes[2,1].scatter(gaussian_data['noise_level'], gaussian_regimes, \n",
    "                      s=150, c='blue', marker='o', label='Gaussian', alpha=0.7)\n",
    "    axes[2,1].scatter(poisson_data['noise_level'], poisson_regimes, \n",
    "                      s=150, c='red', marker='s', label='Poisson', alpha=0.7)\n",
    "    axes[2,1].set_xlabel('Noise Level')\n",
    "    axes[2,1].set_ylabel('Activity Regime')\n",
    "    axes[2,1].set_yticks(range(4))\n",
    "    axes[2,1].set_yticklabels(regime_names)\n",
    "    axes[2,1].set_title('Network Activity Regimes')\n",
    "    axes[2,1].legend()\n",
    "    axes[2,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 9. Delay detection efficacy\n",
    "    def delay_detection_score(cross_corr_peak, lag_ms, expected_delay=6):\n",
    "        \"\"\"Score how well the delay is detected: high correlation + correct lag = high score\"\"\"\n",
    "        lag_accuracy = 1.0 - min(abs(lag_ms - expected_delay) / 20.0, 1.0)  # Penalty for wrong lag\n",
    "        return cross_corr_peak * lag_accuracy\n",
    "    \n",
    "    gaussian_scores = [delay_detection_score(peak, lag) for peak, lag in \n",
    "                       zip(gaussian_data['cross_corr_peak'], gaussian_data['cross_corr_lag_ms'])]\n",
    "    poisson_scores = [delay_detection_score(peak, lag) for peak, lag in \n",
    "                      zip(poisson_data['cross_corr_peak'], poisson_data['cross_corr_lag_ms'])]\n",
    "    \n",
    "    axes[2,2].plot(gaussian_data['noise_level'], gaussian_scores, 'o-', \n",
    "                   label='Gaussian', color='blue', linewidth=2, markersize=8)\n",
    "    axes[2,2].plot(poisson_data['noise_level'], poisson_scores, 's-', \n",
    "                   label='Poisson', color='red', linewidth=2, markersize=8)\n",
    "    axes[2,2].set_xlabel('Noise Level')\n",
    "    axes[2,2].set_ylabel('Delay Detection Score')\n",
    "    axes[2,2].set_title('Delay Detection Efficacy')\n",
    "    axes[2,2].legend()\n",
    "    axes[2,2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{results_dir}/enhanced_trends_analysis.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Generate summary statistics table - FIXED VERSION\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ENHANCED ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"\\nüìä NOISE TYPE COMPARISON:\")\n",
    "    print(f\"{'Metric':<25} {'Gaussian':<15} {'Poisson':<15} {'Difference':<15}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Compare means across noise levels\n",
    "    gaussian_mean_sync = gaussian_data['cross_corr_peak'].mean()\n",
    "    poisson_mean_sync = poisson_data['cross_corr_peak'].mean()\n",
    "    print(f\"{'Synchronization':<25} {gaussian_mean_sync:.3f}{'':<10} {poisson_mean_sync:.3f}{'':<10} {abs(gaussian_mean_sync-poisson_mean_sync):.3f}\")\n",
    "    \n",
    "    gaussian_mean_lag = gaussian_data['cross_corr_lag_ms'].mean()\n",
    "    poisson_mean_lag = poisson_data['cross_corr_lag_ms'].mean()\n",
    "    print(f\"{'Mean Lag (ms)':<25} {gaussian_mean_lag:.1f}{'':<14} {poisson_mean_lag:.1f}{'':<14} {abs(gaussian_mean_lag-poisson_mean_lag):.1f}\")\n",
    "    \n",
    "    gaussian_mean_freq = gaussian_data['firing_rate_exc_A'].mean()\n",
    "    poisson_mean_freq = poisson_data['firing_rate_exc_A'].mean()\n",
    "    print(f\"{'Firing Rate (Hz)':<25} {gaussian_mean_freq:.2f}{'':<12} {poisson_mean_freq:.2f}{'':<12} {abs(gaussian_mean_freq-poisson_mean_freq):.2f}\")\n",
    "    \n",
    "    print(f\"\\nüéØ DELAY DETECTION ANALYSIS:\")\n",
    "    # Find best delay detection for each noise type - FIXED VERSION\n",
    "    if len(gaussian_scores) > 0:\n",
    "        best_gaussian_idx = np.argmax(gaussian_scores)\n",
    "        print(f\"Best Gaussian detection: Noise {gaussian_data.iloc[best_gaussian_idx]['noise_level']} \"\n",
    "              f\"(score: {gaussian_scores[best_gaussian_idx]:.3f}, lag: {gaussian_data.iloc[best_gaussian_idx]['cross_corr_lag_ms']:.0f}ms)\")\n",
    "    else:\n",
    "        print(\"No Gaussian data available\")\n",
    "    \n",
    "    if len(poisson_scores) > 0:\n",
    "        best_poisson_idx = np.argmax(poisson_scores)\n",
    "        print(f\"Best Poisson detection:  Noise {poisson_data.iloc[best_poisson_idx]['noise_level']} \"\n",
    "              f\"(score: {poisson_scores[best_poisson_idx]:.3f}, lag: {poisson_data.iloc[best_poisson_idx]['cross_corr_lag_ms']:.0f}ms)\")\n",
    "    else:\n",
    "        print(\"No Poisson data available\")\n",
    "    \n",
    "    print(f\"\\nüß† REGIME TRANSITIONS:\")\n",
    "    # Ensure we have data to compare\n",
    "    min_len = min(len(gaussian_data), len(poisson_data))\n",
    "    for i in range(min_len):\n",
    "        noise_level = gaussian_data.iloc[i]['noise_level']\n",
    "        g_regime = gaussian_regimes[i] if i < len(gaussian_regimes) else 0\n",
    "        p_regime = poisson_regimes[i] if i < len(poisson_regimes) else 0\n",
    "        print(f\"Noise {noise_level:2d}: {regime_names[g_regime]:12s} ‚Üí {regime_names[p_regime]:12s}\")\n",
    "        \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ef0055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create analyzer and run analysis\n",
    "\n",
    "from metrics import NeuralConnectivityAnalyzer\n",
    "analyzer = NeuralConnectivityAnalyzer(analysis_dt=0.01*ms)  # Use actual dt\n",
    "\n",
    "def run_single_noise_simulation(args):\n",
    "    \"\"\"Worker function for single noise level simulation with proper cleanup\"\"\"\n",
    "    \n",
    "    noise_level, noise_type, config, results_dir = args\n",
    "    \n",
    "    # Initialize Brian2 scope per process\n",
    "    start_scope()\n",
    "    # set_device('cpp_standalone', build_on_run=True)  # Device optimizado\n",
    "    prefs.codegen.target = 'cython' \n",
    "    \n",
    "    try:\n",
    "        print(f\"Worker: Ejecutando noise_level = {noise_level}, type = {noise_type}\")\n",
    "        \n",
    "        # Create simulator\n",
    "        sim = IzhikevichNetwork(dt_val=config['dt_val'], T_total=config['T_total_ms'], seed_val=config['seed_val'])\n",
    "        \n",
    "        # Create populations with specific noise type\n",
    "        pop_A = sim.create_population('A', Ne=config['Ne'], Ni=config['Ni'], \n",
    "                                    k_exc=config['k_factor']*0.5, k_inh=config['k_factor']*1.0,\n",
    "                                    noise_exc=noise_level, noise_inh=noise_level*config['noise_inh_factor'], \n",
    "                                    p_intra=config['p_intra'], delay=config['intra_delay_ms'], \n",
    "                                    noise_type=noise_type)\n",
    "        \n",
    "        pop_B = sim.create_population('B', Ne=config['Ne'], Ni=config['Ni'], \n",
    "                                    k_exc=config['k_factor']*0.5, k_inh=config['k_factor']*1.0,\n",
    "                                    noise_exc=noise_level, noise_inh=noise_level*config['noise_inh_factor'], \n",
    "                                    p_intra=config['p_intra'], delay=config['intra_delay_ms'], \n",
    "                                    noise_type=noise_type)\n",
    "        \n",
    "        # Inter-population connections\n",
    "        syn_AB = sim.connect_populations('A', 'B', p_inter=config['p_inter'], \n",
    "                                       weight_scale=config['k_factor']*config['inter_k_factor'], \n",
    "                                       delay_value=config['delay_ms'])\n",
    "        syn_BA = sim.connect_populations('B', 'A', p_inter=config['p_inter'], \n",
    "                                       weight_scale=config['k_factor']*config['inter_k_factor'], \n",
    "                                       delay_value=config['delay_ms'])\n",
    "        \n",
    "        # Run simulation\n",
    "        sim.setup_monitors(['A', 'B'])\n",
    "        results = sim.run_simulation()\n",
    "        \n",
    "        # Connectivity analysis\n",
    "        condition_name = f\"{noise_type}_{noise_level}\"\n",
    "        \n",
    "        spike_times_A = results['A']['spike_times']\n",
    "        spike_indices_A = results['A']['spike_indices']\n",
    "        spike_times_B = results['B']['spike_times']\n",
    "        spike_indices_B = results['B']['spike_indices']\n",
    "        \n",
    "        # Mock spike monitors for existing analyze_simulation_results function\n",
    "        class MockSpikeMon:\n",
    "            def __init__(self, times, indices):\n",
    "                self.t = times * ms\n",
    "                self.i = indices\n",
    "        \n",
    "        mock_mon_A = MockSpikeMon(spike_times_A, spike_indices_A)\n",
    "        mock_mon_B = MockSpikeMon(spike_times_B, spike_indices_B)\n",
    "        \n",
    "        connectivity_results = analyze_simulation_results(mock_mon_A, mock_mon_B, config['N_total'], condition_name)\n",
    "        \n",
    "        # Generate raster plot\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        \n",
    "        # Pop A\n",
    "        plt.subplot(1, 2, 1)\n",
    "        exc_mask_A = spike_indices_A < config['Ne']\n",
    "        inh_mask_A = spike_indices_A >= config['Ne']\n",
    "        \n",
    "        plt.plot(spike_times_A[exc_mask_A], spike_indices_A[exc_mask_A], '.k', markersize=0.7)\n",
    "        plt.plot(spike_times_A[inh_mask_A], spike_indices_A[inh_mask_A], '.k', markersize=0.7)\n",
    "        plt.axhline(y=config['Ne'], color='r', linestyle='-', linewidth=1)\n",
    "        plt.xlabel('Tiempo (ms)')\n",
    "        plt.ylabel('Neuronas A')\n",
    "        plt.title('Population A')\n",
    "        plt.ylim(0, config['N_total'])\n",
    "\n",
    "        # Pop B\n",
    "        plt.subplot(1, 2, 2)\n",
    "        exc_mask_B = spike_indices_B < config['Ne']\n",
    "        inh_mask_B = spike_indices_B >= config['Ne']\n",
    "        \n",
    "        plt.plot(spike_times_B[exc_mask_B], spike_indices_B[exc_mask_B], '.k', markersize=0.7)\n",
    "        plt.plot(spike_times_B[inh_mask_B], spike_indices_B[inh_mask_B], '.k', markersize=0.7)\n",
    "        plt.axhline(y=config['Ne'], color='r', linestyle='-', linewidth=1)\n",
    "        plt.xlabel('Tiempo (ms)')\n",
    "        plt.ylabel('Neuronas B')\n",
    "        plt.title('Population B')\n",
    "        plt.ylim(0, config['N_total'])\n",
    "        \n",
    "        plt.suptitle(f'Raster Plot - {noise_type.title()} Noise Level {noise_level}', fontsize=16)\n",
    "        \n",
    "        # Save raster plot\n",
    "        raster_filename = f\"{results_dir}/rasters/raster_{noise_type}_{noise_level}.png\"\n",
    "        plt.savefig(raster_filename, dpi=300, bbox_inches='tight')\n",
    "        plt.close()  # Important: close figure to free memory\n",
    "        \n",
    "        # Network statistics\n",
    "        import io\n",
    "        import sys\n",
    "        old_stdout = sys.stdout\n",
    "        sys.stdout = buffer = io.StringIO()\n",
    "        \n",
    "        network_stats = print_network_statistics_table(results, sim, config['Ne'], config['Ni'], \n",
    "                                                      config['T_total_ms'], config['warmup_ms'])\n",
    "        \n",
    "        sys.stdout = old_stdout\n",
    "        stats_output = buffer.getvalue()\n",
    "        \n",
    "        print(f\"Worker: ‚úì Completado {noise_type}_{noise_level}\")\n",
    "        \n",
    "        # Prepare return data\n",
    "        return_data = {\n",
    "            'noise_level': noise_level,\n",
    "            'noise_type': noise_type,\n",
    "            'condition_name': condition_name,\n",
    "            'connectivity_results': connectivity_results,\n",
    "            'network_stats': network_stats,\n",
    "            'stats_output': stats_output,\n",
    "            'raster_saved': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Worker: ‚ùå Error en {noise_type}_{noise_level}: {str(e)}\")\n",
    "        return_data = {\n",
    "            'noise_level': noise_level,\n",
    "            'noise_type': noise_type,\n",
    "            'condition_name': f\"{noise_type}_{noise_level}\",\n",
    "            'connectivity_results': None,\n",
    "            'network_stats': None,\n",
    "            'stats_output': f\"Error: {str(e)}\",\n",
    "            'raster_saved': False\n",
    "        }\n",
    "    \n",
    "    finally:\n",
    "        # ============= RESOURCE CLEANUP =============\n",
    "        \n",
    "        # 1. Clear Brian2 scope and devices\n",
    "        try:\n",
    "            from brian2 import clear_cache, device\n",
    "            clear_cache('codeobj')  # Clear code object cache\n",
    "            if hasattr(device, 'reinit'):\n",
    "                device.reinit()\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 2. Close any remaining matplotlib figures\n",
    "        plt.close('all')\n",
    "        \n",
    "        # 3. Clear large variables from memory\n",
    "        try:\n",
    "            del sim, results, spike_times_A, spike_indices_A\n",
    "            del spike_times_B, spike_indices_B, connectivity_results\n",
    "            del mock_mon_A, mock_mon_B, analyzer\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # 4. Force garbage collection\n",
    "        import gc\n",
    "        gc.collect()\n",
    "        \n",
    "        # 5. Reset random seeds (optional but good practice)\n",
    "        import numpy as np\n",
    "        np.random.seed(None)\n",
    "        \n",
    "        print(f\"Worker: üßπ Recursos limpiados para {noise_type}_{noise_level}\")\n",
    "        \n",
    "        # ============================================\n",
    "    \n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0958fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment_5_parallel():\n",
    "    \"\"\"Experimento 5 paralelo: Efecto del delay en diferentes reg√≠menes de actividad\"\"\"\n",
    "    \n",
    "    # ========== CONFIGURATION VARIABLES ==========\n",
    "    # Experiment parameters\n",
    "    noise_types = ['gaussian', 'poisson']\n",
    "    noise_levels = [10, 18]\n",
    "    delay_ms = 6\n",
    "    k_factor = 20\n",
    "    inter_k_factor = 5.0\n",
    "    \n",
    "    # Simulation parameters\n",
    "    dt_val = 0.01\n",
    "    T_total_ms = 1200\n",
    "    warmup_ms = 200\n",
    "    seed_val = 42\n",
    "    \n",
    "    # Population parameters\n",
    "    Ne = 800\n",
    "    Ni = 200\n",
    "    N_total = Ne + Ni\n",
    "    \n",
    "    # Connectivity parameters\n",
    "    p_intra = 0.1\n",
    "    p_inter = 0.01\n",
    "    intra_delay_ms = 0.2\n",
    "    \n",
    "    # Noise parameters\n",
    "    noise_inh_factor = 0.45\n",
    "    \n",
    "    # Analysis parameters\n",
    "    max_lag_ms = 120\n",
    "    smooth_window = 5\n",
    "    nperseg_coherence = 1024\n",
    "    nperseg_psd = 512\n",
    "    # =============================================\n",
    "    \n",
    "    # Create configuration object\n",
    "    config = {\n",
    "        'delay_ms': delay_ms,\n",
    "        'k_factor': k_factor,\n",
    "        'inter_k_factor': inter_k_factor,\n",
    "        'dt_val': dt_val,\n",
    "        'T_total_ms': T_total_ms,\n",
    "        'warmup_ms': warmup_ms,\n",
    "        'seed_val': seed_val,\n",
    "        'Ne': Ne,\n",
    "        'Ni': Ni,\n",
    "        'N_total': N_total,\n",
    "        'p_intra': p_intra,\n",
    "        'p_inter': p_inter,\n",
    "        'intra_delay_ms': intra_delay_ms,\n",
    "        'noise_inh_factor': noise_inh_factor,\n",
    "        'max_lag_ms': max_lag_ms,\n",
    "        'smooth_window': smooth_window,\n",
    "        'nperseg_coherence': nperseg_coherence,\n",
    "        'nperseg_psd': nperseg_psd\n",
    "    }\n",
    "    \n",
    "    # Create results directory\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    results_dir = f\"./results/experiment_noise_comparison_{timestamp}\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    os.makedirs(results_dir+\"/rasters/\", exist_ok=True)\n",
    "    \n",
    "    print(f\"=== EXPERIMENTO: GAUSSIAN vs POISSON NOISE (PARALELO) ===\")\n",
    "    print(f\"Delay fijo: {delay_ms}ms\")\n",
    "    print(f\"Noise types: {noise_types}\")\n",
    "    print(f\"Noise levels: {noise_levels}\")\n",
    "    print(f\"Total simulaciones: {len(noise_types) * len(noise_levels)}\")\n",
    "    print(f\"Resultados guardados en: {results_dir}\")\n",
    "    \n",
    "    # Parallel execution\n",
    "    print(f\"\\n--- Ejecutando simulaciones en paralelo ---\")\n",
    "    \n",
    "    # Prepare arguments for all combinations\n",
    "    worker_args = []\n",
    "    for noise_type in noise_types:\n",
    "        for noise_level in noise_levels:\n",
    "            worker_args.append((noise_level, noise_type, config, results_dir))\n",
    "    \n",
    "    with Pool(processes=len(worker_args)) as pool:\n",
    "        worker_results = pool.map(run_single_noise_simulation, worker_args)\n",
    "    \n",
    "    # Merge results\n",
    "    print(\"\\n--- Procesando resultados ---\")\n",
    "    \n",
    "    all_connectivity_results = {}\n",
    "    all_network_stats = {}\n",
    "    \n",
    "    for result in worker_results:\n",
    "        condition = result['condition_name']\n",
    "        all_connectivity_results[condition] = result['connectivity_results']\n",
    "        all_network_stats[condition] = result['network_stats']\n",
    "        \n",
    "        # Print individual stats\n",
    "        print(result['stats_output'])\n",
    "        \n",
    "        # Move raster plots to results directory\n",
    "        old_path = f\"raster_noise_{result['noise_level']}.png\"\n",
    "        new_path = f\"{results_dir}/raster_noise_{result['noise_level']}.png\"\n",
    "        try:\n",
    "            import shutil\n",
    "            shutil.move(old_path, new_path)\n",
    "        except:\n",
    "            print(f\"Warning: Could not move {old_path}\")\n",
    "    \n",
    "    # Generate connectivity dashboard\n",
    "    print(\"\\n--- Generando dashboard de conectividad ---\")\n",
    "    \n",
    "    fig1 = plot_connectivity_dashboard(all_connectivity_results, figsize=(18, 12))\n",
    "    fig1.suptitle('Experiment 5: Connectivity Analysis Across Noise Levels', fontsize=16)\n",
    "    fig1.savefig(f\"{results_dir}/connectivity_dashboard.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create summary table\n",
    "    summary_data = create_summary_table(all_connectivity_results, all_network_stats)\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.to_csv(f\"{results_dir}/summary_metrics.csv\", index=False)\n",
    "    \n",
    "    # Generate trends plot\n",
    "    plot_summary_trends(summary_df, results_dir)\n",
    "    \n",
    "    # Save comprehensive configuration\n",
    "    final_config = {\n",
    "        'experiment': 'R√©gimen de Actividad (Paralelo)',\n",
    "        'timestamp': timestamp,\n",
    "        'parallel': True,\n",
    "        'noise_levels': noise_levels,\n",
    "        \n",
    "        # All configuration variables automatically included\n",
    "        **config\n",
    "    }\n",
    "    \n",
    "    with open(f\"{results_dir}/experiment_config.json\", 'w') as f:\n",
    "        json.dump(final_config, f, indent=2)\n",
    "    \n",
    "    print(f\"\\n‚úì Experimento paralelo completado!\")\n",
    "    print(f\"üìÅ Resultados guardados en: {results_dir}\")\n",
    "    print(f\"üìä Archivos generados:\")\n",
    "    print(f\"  - connectivity_dashboard.png\")\n",
    "    print(f\"  - summary_metrics.csv\")\n",
    "    print(f\"  - trends_summary.png\")\n",
    "    print(f\"  - experiment_config.json\")\n",
    "    print(f\"  - raster_noise_*.png\")\n",
    "    \n",
    "    # Print comprehensive summary\n",
    "    print_experiment_summary(all_connectivity_results, summary_df, results_dir, delay_ms, noise_levels)\n",
    "    \n",
    "    return all_connectivity_results, summary_df, results_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90b4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar experimento paralelo\n",
    "connectivity_results, summary_df, results_dir = run_experiment_5_parallel()\n",
    "\n",
    "# Mostrar resumen final\n",
    "print(\"\\n=== RESUMEN CUANTITATIVO ===\")\n",
    "print(summary_df[['noise_level', 'cross_corr_peak', 'plv_alpha', 'firing_rate_exc_A', 'cv_A']].round(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86fd1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_analysis_results(results_dict, summary_df):\n",
    "    \"\"\"Comprehensive validation of analysis results\"\"\"\n",
    "    \n",
    "    print(\"=== VALIDATION REPORT ===\\n\")\n",
    "    \n",
    "    # 1. Cross-correlation lag validation\n",
    "    print(\"1. CROSS-CORRELATION LAGS:\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "        lag = row['cross_corr_lag_ms']\n",
    "        condition = row['condition']\n",
    "        expected_delay = 6  # ms\n",
    "        \n",
    "        if abs(lag) > 20:\n",
    "            print(f\"  ‚ùå {condition}: lag={lag:.1f}ms (too high)\")\n",
    "        elif lag < 0:\n",
    "            print(f\"  ‚ö†Ô∏è  {condition}: lag={lag:.1f}ms (negative - check causality)\")\n",
    "        elif abs(lag - expected_delay) < 2:\n",
    "            print(f\"  ‚úÖ {condition}: lag={lag:.1f}ms (close to expected)\")\n",
    "        else:\n",
    "            print(f\"  ‚ö†Ô∏è  {condition}: lag={lag:.1f}ms (deviation from expected)\")\n",
    "    \n",
    "    # 2. PLV/PLI consistency validation\n",
    "    print(\"\\n2. PLV/PLI CONSISTENCY:\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "        plv = row['plv_alpha']\n",
    "        pli = row['pli_alpha']\n",
    "        condition = row['condition']\n",
    "        \n",
    "        if pli > plv + 0.1:  # PLI shouldn't exceed PLV significantly\n",
    "            print(f\"  ‚ùå {condition}: PLI({pli:.3f}) > PLV({plv:.3f}) - impossible\")\n",
    "        elif abs(plv - pli) > 0.5:  # Large differences suspicious\n",
    "            print(f\"  ‚ö†Ô∏è  {condition}: PLV({plv:.3f}) vs PLI({pli:.3f}) - large diff\")\n",
    "        else:\n",
    "            print(f\"  ‚úÖ {condition}: PLV({plv:.3f}), PLI({pli:.3f}) - consistent\")\n",
    "    \n",
    "    # 3. Firing rate vs CV relationship\n",
    "    print(\"\\n3. FIRING RATE vs CV RELATIONSHIP:\")\n",
    "    for _, row in summary_df.iterrows():\n",
    "        firing_rate = row['firing_rate_exc_A']\n",
    "        cv = row['cv_A']\n",
    "        noise_level = row['noise_level']\n",
    "        noise_type = row['noise_type']\n",
    "        \n",
    "        print(f\"  {noise_type}_{noise_level}: Rate={firing_rate:.1f}Hz, CV={cv:.3f}\")\n",
    "    \n",
    "    # Check if CV decreases with noise (suspicious)\n",
    "    gaussian_data = summary_df[summary_df['noise_type'] == 'gaussian'].sort_values('noise_level')\n",
    "    poisson_data = summary_df[summary_df['noise_type'] == 'poisson'].sort_values('noise_level')\n",
    "    \n",
    "    print(\"\\n4. CV TREND VALIDATION:\")\n",
    "    for data, name in [(gaussian_data, 'Gaussian'), (poisson_data, 'Poisson')]:\n",
    "        cv_values = data['cv_A'].values\n",
    "        if len(cv_values) > 1:\n",
    "            trend = \"decreasing\" if cv_values[-1] < cv_values[0] else \"increasing\"\n",
    "            print(f\"  {name}: CV trend is {trend} with noise level\")\n",
    "            if trend == \"decreasing\":\n",
    "                print(f\"    ‚ö†Ô∏è  This is counterintuitive - needs investigation\")\n",
    "    \n",
    "    # 5. Coherence peaks validation\n",
    "    print(\"\\n5. COHERENCE PEAK VALIDATION:\")\n",
    "    peak_freqs = summary_df['coherence_freq_hz'].values\n",
    "    unique_peaks = np.unique(peak_freqs)\n",
    "    \n",
    "    print(f\"  Unique peak frequencies: {unique_peaks}\")\n",
    "    if len(unique_peaks) < 3:\n",
    "        print(f\"  ‚ö†Ô∏è  Too few unique peaks - possible discretization artifact\")\n",
    "    \n",
    "    # Count zeros and repeated values\n",
    "    zero_count = np.sum(peak_freqs == 0.0)\n",
    "    repeated_13_count = np.sum(peak_freqs == 13.333333333333334)\n",
    "    \n",
    "    print(f\"  Peaks at 0.0Hz: {zero_count}/{len(peak_freqs)}\")\n",
    "    print(f\"  Peaks at 13.3Hz: {repeated_13_count}/{len(peak_freqs)}\")\n",
    "    \n",
    "    if zero_count > len(peak_freqs)//2:\n",
    "        print(f\"    ‚ùå Too many zero-frequency peaks - check spectral analysis\")\n",
    "    \n",
    "    # 6. Activity regime validation\n",
    "    print(\"\\n6. ACTIVITY REGIME VALIDATION:\")\n",
    "    def correct_classify_regime(firing_rate):\n",
    "        if firing_rate < 0.5:\n",
    "            return \"Silent\"\n",
    "        elif firing_rate < 2.0:\n",
    "            return \"Low Active\"  \n",
    "        elif firing_rate < 15.0:\n",
    "            return \"Active\"\n",
    "        else:\n",
    "            return \"Bursting\"\n",
    "    \n",
    "    for _, row in summary_df.iterrows():\n",
    "        firing_rate = row['firing_rate_exc_A']\n",
    "        reported_regime = row['sync_level_A']  # This seems wrong - should be activity level\n",
    "        correct_regime = correct_classify_regime(firing_rate)\n",
    "        condition = row['condition']\n",
    "        \n",
    "        print(f\"  {condition}: Rate={firing_rate:.1f}Hz ‚Üí Should be '{correct_regime}'\")\n",
    "    \n",
    "    # 7. Timescale validation\n",
    "    print(\"\\n7. INTRINSIC TIMESCALE VALIDATION:\")\n",
    "    timescales_A = summary_df['timescale_A_ms'].values\n",
    "    timescales_B = summary_df['timescale_B_ms'].values\n",
    "    \n",
    "    print(f\"  Timescale A range: {np.min(timescales_A):.1f} - {np.max(timescales_A):.1f} ms\")\n",
    "    print(f\"  Timescale B range: {np.min(timescales_B):.1f} - {np.max(timescales_B):.1f} ms\")\n",
    "    \n",
    "    # Check if all are very similar (suspicious)\n",
    "    if (np.max(timescales_A) - np.min(timescales_A)) < 10:\n",
    "        print(f\"    ‚ö†Ô∏è  Very narrow range for timescales A - check calculation\")\n",
    "    \n",
    "    # 8. Summary recommendations\n",
    "    print(\"\\n=== RECOMMENDATIONS ===\")\n",
    "    print(\"1. Recalculate cross-correlation with proper lag normalization\")\n",
    "    print(\"2. Verify PLV/PLI calculation - use different frequency bands\")\n",
    "    print(\"3. Check CV calculation - should increase with noise level\")\n",
    "    print(\"4. Fix activity regime classification logic\")\n",
    "    print(\"5. Investigate coherence discretization artifacts\")\n",
    "    print(\"6. Validate spectral analysis parameters (nperseg, fs)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Additional function to check raw data integrity\n",
    "def check_spike_data_integrity(results):\n",
    "    \"\"\"Check if spike data makes sense\"\"\"\n",
    "    print(\"\\n=== SPIKE DATA INTEGRITY ===\")\n",
    "    \n",
    "    for pop_name in ['A', 'B']:\n",
    "        spike_times = results[pop_name]['spike_times']\n",
    "        spike_indices = results[pop_name]['spike_indices']\n",
    "        \n",
    "        print(f\"\\nPopulation {pop_name}:\")\n",
    "        print(f\"  Total spikes: {len(spike_times)}\")\n",
    "        print(f\"  Time range: {np.min(spike_times):.1f} - {np.max(spike_times):.1f} ms\")\n",
    "        print(f\"  Neuron range: {np.min(spike_indices)} - {np.max(spike_indices)}\")\n",
    "        \n",
    "        # Check for anomalies\n",
    "        if len(spike_times) == 0:\n",
    "            print(f\"    ‚ùå No spikes detected!\")\n",
    "        elif np.max(spike_indices) >= 1000:\n",
    "            print(f\"    ‚ùå Neuron indices exceed population size!\")\n",
    "        elif np.min(spike_times) < 0:\n",
    "            print(f\"    ‚ùå Negative spike times!\")\n",
    "        else:\n",
    "            print(f\"    ‚úÖ Spike data looks valid\")\n",
    "\n",
    "# Usage in your experiment:\n",
    "validate_analysis_results(connectivity_results, summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823769e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_spike_data_integrity(connectivity_results['gaussian_10'])  # For one set of results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.10.13)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
